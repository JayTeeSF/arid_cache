= AridCache

AridCache makes caching easy and effective.  AridCache supports caching on all of your ActiveRecord model named scopes, class and instance methods right out of the box.  AridCache keeps caching logic out of your model methods and clarifies your view code by making calls to cached result sets explicit.

AridCache supports caching large, expensive ActiveRecord collections by caching only the model IDs, provides efficient in-memory pagination of your cached collections, and gives you collection counts for free.  Non-ActiveRecord collection data is cached unchanged allowing you to cache the results of any expensive operation simply by prepending your method call with <tt>cached_</tt>.

AridCache simplifies caching by supporting auto-expiring cache keys - as well as common options like <tt>:expires_in</tt> - and provides methods to help you manage your caches at the global, model class, model instance and per-cache level.

== Install

Add this to your <tt>config/environment.rb</tt> file:
  
  config.gem 'arid_cache'
  
Then

  rake gems:install

(Requires having GemCutter in your gem sources.)

== Why AridCache?

The name AridCache comes from <b>A</b>ctive<b>R</b>ecord *ID* Cache.  It's also very DRY...get it? :)

== Defining Caches

Out of the box AridCache supports caching on all your ActiveRecord class and instance methods and named scopes...basically if a class or class instance <tt>respond_to?</tt> something, you can cache it. You can also define caches that use compositions of methods or named scopes for those cases when you don't want to add a new method to your class.

==== Cached results

* If the result of your <tt>cached_</tt> call is an array of ActiveRecord records, AridCache only stores the IDs in the cache, because it's a bad idea to store records in the cache.  Arrays of other types are stored as-is so you can still cache arrays of strings and other types.

On subsequent calls we call <tt>find</tt> on the target class passing in the ActiveRecord IDs that were stored in the cache. One implication is that an <tt>:order</tt> clause that ordered the initial results isn't applied on subsequent calls, so it's a good idea to always include an <tt>:order</tt> option when calling <tt>cached_</tt>.  This is also true for options like <tt>:include</tt>.  It means theres some duplication of query options, but I don't know if that can be avoided.

* Everything else is cached and returned as-is.

An example of caching using existing methods on your class:

  class User < ActiveRecord::Base
    has_many    :pets
    has_one     :preferences
    named_scope :active, :conditions => [ 'updated_at <= ', 5.minutes.ago ]
  end

  User.cached_count          # uses the built-in count method
  User.cached_active         # only stores the IDs of the active users in the cache
  User.cached_active_count   # returns the count of active users directly from the cache

  user.cached_pets_count     # only selects the count until the collection is requested
  user.cached_pets           # loads the collection and stores the pets IDs in the cache
  
==== Dynamically defining caches

To dynamically define caches just pass a block to your <tt>cached_</tt> calls.  Caches can be defined on your classes or class instances.  For example,

  User.cached_most_active_users do
    active.find(:order => 'activity DESC', :limit => 5)
  end
  
  => [#<User id: 23>, #<User id: 30>, #<User id: 5>, #<User id: 2>, #<User id: 101>]
  
  user.cached_favorite_pets do
    pets.find(:all, :conditions => { 'favorite' => true })
  end
  
  => [#<Pet id: 11>, #<Pet id: 21>, #<Pet id: 3>]

==== A more complex example

These dynamic caches make use of other cached collections.

  @tracks  = @genre.cached_highlight_tracks(:order => 'release_date DESC', :include => [:album, :artist]) do
    cached_tracks(:order => 'release_date DESC', :limit => 10, :include => [:album, :artist])
  end
  @artists = @genre.cached_highlight_artists do
    cached_artists(:limit => 10)
  end
  @albums  = @genre.cached_highlight_albums(:order => 'release_date DESC', :include => :artist) do
    cached_albums(:order => 'release_date DESC', :limit => 3, :include => :artist)
  end

==== Configuring caches

We can clean up our views significantly by configuring caches on our model rather than defining them dynamically and passing options in each time.  You configure caches by calling <tt>instance_caches</tt> or <tt>class_caches</tt> and passing in a block where you define your caches.  Options passed in here are applied to all subsequent calls to the corresponding <tt>cached_</tt> methods.

You can pass a hash of options to <tt>instance_caches</tt> and <tt>class_caches</tt> to have those options applied to all caches in the block.

  class Genre
    instance_caches do
      @order = 'release_date DESC'
      highlight_tracks(:order => @order, :include => [:album, :artist]) do
        cached_tracks(:order => 'release_date DESC', :limit => 10, :include => [:album, :artist])
      end
      highlight_artists do
        cached_artists(:limit => 10)
      end
      highlight_albums(:order => @order, :include => :artist) do
        cached_albums(:order => 'release_date DESC', :limit => 3, :include => :artist)
      end
    end
  end
  
  @tracks  = @genre.cached_highlight_tracks
  @artists = @genre.cached_highlight_artists
  @albums  = @genre.cached_highlight_albums



==  Cache Keys & Managing your Caches

==== Cache Keys

AridCache cache keys are defined based on the methods you call to interact with the cache.  For example:

  Album.cached_featured_albums  => cache key is arid-cache-album-featured_albums
  album.cached_top_tracks       => cache key is like arid-cache-albums/2-20090930200-top_tracks
    
Caches on model instances automatically incorporate the ActiveRecord <tt>cache_key</tt> which includes the <tt>updated_at</tt> timestamp of that instance, making them auto-expire when the instance is updated.  (There will soon be an option to turn off this behaviour.)

Caches on your model classes (like on the results of named scopes) will not expire.  (I will soon add support for passing an <tt>:expires_in</tt> option to the cache store.)
  
==== Managing your Caches

AridCache provides these methods to help you manage your caches:
  
  AridCache.clear_caches      => expires all AridCache caches
  Model.clear_caches          => expires class and instance-level caches for this model
  Model.clear_instance_caches => expires instance-level caches for this model
  Model.clear_class_caches    => expires class-level caches for this model
  
(The <tt>Model.clear_caches</tt> methods are also available on your model instances.)

Alternatively you can pass a <tt>:force => true</tt> option in your <tt>cached_</tt> calls to force a refresh of a particular cache.  For example:

  Album.cached_featured_albums(:force => true)
  album.cached_top_tracks(:force => true)

== Cached Counts

AridCache gives you counts for free.  When a large collection is stored in the cache
AridCache stores the count as well so the next time you want request the count it
just takes a single read from the cache.  This is also supported for your non-ActiveRecord
collections if the collection <tt>responds_to?(:count)</tt>.

Given that we have a cache like <tt>album.cached_tracks</tt> we can get the count by calling <tt>album.cached_tracks_count</tt>.

In the case of a non-ActiveRecord collection such as <tt>album.cached_similar_genres</tt> which returns a list like <tt>['Pop', 'Rock', 'Rockabilly']</tt> we can get the cached length of this list with <tt>album.cached_similar_genres_count</tt>.

Sometimes you may want the collection count without loading and caching the collection.  AridCache is smart enough that if you only ask for a count - and the collection hasn't already been cached - it will only query for the count.  This is only possible if the return value of your method is a named scope or association proxy (since these are lazy-loaded unlike a call to <tt>find()</tt>).  In the example above if we only ever call <tt>album.cached_tracks_count</tt>, only the count will be cached.  If we subsequently call <tt>album.cached_tracks</tt> the collection will be loaded and the IDs cached as per normal.

Other methods for caching counts are provided for us by virtue of ActiveRecord's built-in methods and named scopes.  For instance, to cache the count for a particular model we can call <tt>Artist.cached_count</tt>.

== Pagination Support and Options to <tt>find</tt>

AridCache supports pagination using WillPaginate.  The IDs from the cache are paginated in memory and only that page is selected from the database - directly from the target table, without any expensive joins.

You can also use the <tt>:limit</tt> and <tt>:offset</tt> options.  Again, the IDs from the cache are paginated in memory and only the requested records are selected from the database.
  
You can pass options like <tt>:include</tt> (or any other valid <tt>find</tt> options) to augment the results of your cached query.  Just because all of the options are supported, does not mean it's a good idea to use them.  Take a look at your logs to see how AridCache is interacting with the cache and the database if you don't get the results you expect.

For example, assume we have a <tt>named_scope :active</tt> on <tt>User</tt> which gives the active users.  We can call:
  
  User.cached_active.paginate(:page => 1, :include => :preferences, :per_page => 10)
  User.cached_active(:limit => 10, :offset => 0, :include => :preferences)

(These calls return similar results, except that the first call returns a <tt>WillPaginate::Collection</tt> and the second just returns an <tt>Array</tt>.)
  
== Efficiency

* AridCache intercepts calls to <tt>cached_</tt> methods using <tt>method_missing</tt> then defines those methods on your models as they are called, so they bypass method missing on subsequent calls.
* In-memory pagination of cached collections speeds up your queries.  See _Pagination_.
* If you only request a count AridCache will only select the count.  See <i>Cached Counts</i>.
* If a collection has already been loaded, you get the count for free.  See <i>Cached Counts</i>.

== Known Issues

1. If you are caching a query which returns duplicate records (for example from the result of a join), subsequent calls to the cache will only return unique records.  This is because of the way <tt>find</tt> works when selecting multiple ids.  For example, <tt>user.find([1,1,1])</tt> returns <tt>[#<User id: 1>]</tt>, not <tt>[#<User id: 1>, #<User id: 1>, #<User id: 1>]</tt> as would have been returned from your initial query.

== Examples

==== Given the following model:

  class User < ActiveRecord::Base
    has_many    :pets
    has_one     :preferences
    named_scope :active, :conditions => [ 'updated_at <= ', 5.minutes.ago ]
  end

==== AridCache supports these methods (and many more):
 
  User.cached_count
  User.cached_active         # caches the user IDs and the count
  User.cached_active_count   # gets the count for free

  user.cached_pets           # caches the pets IDs and the count
  user.cached_pets_count     # gets the count for free
   
When we call these methods again, instead of doing a full select - usually including
complex joins or over very large tables which makes this expensive - it just
selects where the IDs are the cached IDs.

It also gives you paging using WillPaginate.  The IDs from the cache are paginated and
only that page is selected from the database - again directly from the table, without
any complex joins.

==== Some examples of pagination:

  User.cached_active.paginate(:page => 1, :per_page => 30)
  User.cached_active.paginate(:page => 1)
  User.cached_active.paginate(:page => 3)

You can also include options for find, such as <tt>:join</tt>, <tt>:include</tt> and <tt>order</tt>...basically any options that find supports.

  User.cached_active.paginate(:page => 1, :include => :preferences)
  User.cached_active.paginate(:page => 1, :order => 'created_at DESC') # don't change the order, just enforce it

You can limit the results returned using <tt>:limit</tt> and <tt>:offset</tt>:

  user.cached_pets(:limit => 2, :include => :toys)
  user.cached_pets(:limit => 2, :offset => 3, :include => :toys)
  
==== You can dynamically create caches

  User.cached_most_active_users do
    self.active.find(:order => 'activity DESC', :limit => 10)
  end

Dynamic caches that make use of other cached collections:

  @tracks  = @genre.cached_highlight_tracks(:order => 'release_date DESC', :include => [:album, :artist]) do
    cached_tracks(:order => 'release_date DESC', :limit => 10, :include => [:album, :artist])
  end
  @artists = @genre.cached_highlight_artists do
    cached_artists(:limit => 10)
  end
  @albums  = @genre.cached_highlight_albums(:order => 'release_date DESC', :include => :artist) do
    cached_albums(:order => 'release_date DESC', :limit => 3, :include => :artist)
  end
    
== Coming Soon

* Configure your caches on your models (or anywhere else you like) by calling <tt>cache_</tt> methods and passing in options which are applied to all subsequent <tt>cached_</tt> calls on that cache.
* Pass <tt>:expires_in</tt> options to the cache store to support expiring caches.
* Support an <tt>:autoexpire => false</tt> option to turn off automatically including the <tt>updated_at</tt> timestamp in the cache key on instance caches.
* Expanded docs.
  
== Contributions

Contributions are welcome!  Please,

* Fork the project.
* Make your feature addition or bug fix.
* Add tests for it (this is important so I don't break it in a future release).
* Commit (don't mess with the Rakefile, version, or history).
* Send me a pull request.

== Copyright

Copyright (c) 2009 Karl Varga. See LICENSE for details.
